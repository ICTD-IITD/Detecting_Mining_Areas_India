{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GEE_generalised.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python386jvsc74a57bd0fc3b895873e97c372ea548667780db68e1b1e3b7fea6f9f1808d2357a4d1acd2",
      "display_name": "Python 3.8.6 64-bit ('seg': conda)"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nghiTDtX6TQ"
      },
      "source": [
        "# Forming Groups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_8uHPq0TlKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8485cd-ad30-4954-dc54-f34f7e5628c3"
      },
      "source": [
        "\"\"\" Run on Google Colab \"\"\"\n",
        "!pip install rasterio\n",
        "!pip install geopandas\n",
        "!pip install geojson"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiBX7EmKVqLC"
      },
      "source": [
        "import rasterio\n",
        "from rasterio.plot import reshape_as_image\n",
        "import rasterio.mask\n",
        "from rasterio.features import rasterize\n",
        "from rasterio.plot import show\n",
        "\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import geojson\n",
        "import json\n",
        "from shapely.geometry import mapping, Point, Polygon\n",
        "from shapely.ops import cascaded_union\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sin, cos, sqrt, atan2, radians, pi, isclose\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOfqAs6OlABi"
      },
      "source": [
        "# Converting Mining Polygons to Geopandas file\n",
        "\n",
        "### Ignore this section (need to done to add grId to mining_polygons) --- Already done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC54tr8_k_gs",
        "outputId": "8dd6d3a7-ca3a-4ace-f1c0-2d3059191fef"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/BTP/DataSet/mining_polygons.geojson\") as f:\n",
        "    gj = geojson.load(f)\n",
        "features = gj['features']\n",
        "for i in range(len(features)):\n",
        "    features[i]['properties']['grId'] = -1\n",
        "    features[i]['type'] = \"Feature\"\n",
        "features[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbWpiZ_bm679"
      },
      "source": [
        "geojson_dict = '{\"type\": \"FeatureCollection\",\"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\" } },\"features\": []}'\n",
        "geojson_obj = json.loads(geojson_dict)\n",
        "geojson_obj['features'] = features\n",
        "geojson_obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7_IEakaotLS"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/BTP/DataSet/all_polygons_init.geojson\", \"w\") as out_file:\n",
        "    geojson.dump(geojson_obj,out_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "kzRYg_vOpSCR",
        "outputId": "95ef6fdb-d890-46e2-d59e-fe980e8658f7"
      },
      "source": [
        "shape_path = \"/content/drive/MyDrive/BTP/DataSet/all_polygons_init.geojson\"\n",
        "df = gpd.read_file(shape_path)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXjPg9ZFlGB-"
      },
      "source": [
        "# Processing the init geojson to make group of mines\n",
        "\n",
        "### Below code runs on indian_polygons_init which is same all_polygons_init\\[all_polygons_init\\['COUNTRY'] == \"India\"\\]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "Grj4BMz4Vrj4",
        "outputId": "d1327a53-4c8a-4153-e0ef-87080ee16cbc"
      },
      "source": [
        "shape_path = \"/content/drive/MyDrive/BTP/DataSet/indian_polygons_init.geojson\"\n",
        "df = gpd.read_file(shape_path)\n",
        "df "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGZcly9mVu74",
        "outputId": "e5f2a69e-2d89-4bd8-d013-4fd5a712ef15"
      },
      "source": [
        "#list of lat,lan\n",
        "train = np.zeros((781,2))\n",
        "for ind,row in df.iterrows():\n",
        "    x,y = df.geometry[ind].exterior.coords.xy\n",
        "    train[ind][0] = np.average(np.array(x))\n",
        "    train[ind][1] = np.average(np.array(y))\n",
        "print(train.shape)\n",
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa3zqPcVW9DP",
        "outputId": "8e66d51f-85b1-4a6f-ffaa-5ed1062f322d"
      },
      "source": [
        "clustering=KMeans(n_clusters=170)\n",
        "clustering.fit(train)\n",
        "print(clustering.labels_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZC43iOmXGGS"
      },
      "source": [
        "#new_df with new labels as per generated by kmean clustering\n",
        "new_df = df.copy()\n",
        "for i in range(781):\n",
        "    new_df.at[i,'grId'] = clustering.labels_[i]\n",
        "new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXmX8MFQXK3E"
      },
      "source": [
        "# Saving new_df for debugging purposes (maintain same grId)\n",
        "# new_df.to_file(\"/content/drive/MyDrive/BTP/DataSet/indian_polygon_with_grId.geojson\", driver='GeoJSON')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "XE1h0zBb2him",
        "outputId": "4759e964-16b1-4bb3-b6a0-e3040ddf16c5"
      },
      "source": [
        "#loading new_df from saved file\n",
        "new_df = gpd.read_file(\"/content/drive/MyDrive/BTP/DataSet/indian_polygon_with_grId.geojson\")\n",
        "new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiunZT5LXTwM",
        "outputId": "7e811db9-c442-4369-cf09-8fbea307ee58"
      },
      "source": [
        "#curr in (longititude, latitude)\n",
        "def give_polygon_boundary(avg,dx=5,dy=5):\n",
        "    r_earth = 6373  #6378\n",
        "    \n",
        "    lat = avg[1]\n",
        "    lon = avg[0]\n",
        "    \n",
        "    px = lat + (dy / r_earth) * (180 / pi)\n",
        "    py = lon + (dx / r_earth) * (180 / pi) / cos(lat * pi/180)\n",
        "    \n",
        "    nx = lat - (dy / r_earth) * (180 / pi);\n",
        "    ny = lon - (dx / r_earth) * (180 / pi) / cos(lat * pi/180)\n",
        "    \n",
        "    return [[ny,nx],[ny,px],[py,px],[py,nx],[ny,nx]]\n",
        "\n",
        "def give_avg(grId,df):\n",
        "    sum_x = 0\n",
        "    sum_y = 0\n",
        "    sum_len = 0\n",
        "    for _,row in df[df['grId']==grId].iterrows():\n",
        "        x,y = row['geometry'].exterior.coords.xy\n",
        "        assert len(x)==len(y)\n",
        "        sum_x += np.sum(np.array(x))\n",
        "        sum_y += np.sum(np.array(y))\n",
        "        sum_len += len(x)\n",
        "    sum_x /= sum_len\n",
        "    sum_y /= sum_len\n",
        "    return sum_x,sum_y\n",
        "\n",
        "\"\"\"\n",
        "Ignore the below function (was earlier used to check whether the mining site is within 20x20 region of the group)\n",
        "\"\"\"\n",
        "\n",
        "def assertion(grId,df,dx=5,dy=5):\n",
        "#     lon = avg_df[avg_df[2]==grId].iloc[0,0]\n",
        "#     lat = avg_df[avg_df[2]==grId].iloc[0,1]\n",
        "    lon,lat = give_avg(grId,df)\n",
        "    lis = give_polygon_boundary((lon,lat),dx,dy)\n",
        "    upX,loX,upY,loY = lis[2][1],lis[0][1],lis[2][0],lis[0][0]\n",
        "    \n",
        "    def check(pts,up,lo):\n",
        "        pts = np.array(pts)\n",
        "        return np.logical_and(pts>=lo,pts<=up).sum() == pts.size\n",
        "        \n",
        "    \n",
        "    temp_df = df[df['grId']==grId]\n",
        "    for _,row in temp_df.iterrows():\n",
        "        lon_,lat_ = row['geometry'].exterior.coords.xy\n",
        "        assert check(lon_,upY,loY) and check(lat_,upX,loX)\n",
        "  \n",
        "failed_assertion = []\n",
        "group_ids = new_df['grId'].unique()\n",
        "for grId in group_ids:\n",
        "    try:\n",
        "        assertion(grId,new_df,10,10)\n",
        "    except:\n",
        "        failed_assertion.append(grId)\n",
        "print(len(failed_assertion))\n",
        "print(failed_assertion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0UAxi80X_gQ"
      },
      "source": [
        "# Making Square Shapes from Groups\n",
        "\n",
        "### use save_sq_coords_v2 to generate boundary region for the group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfHDpdSBXf56"
      },
      "source": [
        "#Saving geometry as new csv (p1,p2,p3,p4,p5=p1)\n",
        "def save_sq_coords_v1(df,dx=5,dy=5):\n",
        "    group_ids = df['grId'].unique()\n",
        "    master_lis = []\n",
        "    for grId in group_ids:\n",
        "        lon,lat = give_avg(grId,df)\n",
        "        lis = give_polygon_boundary((lon,lat),dx,dy)\n",
        "        lis.append([grId])\n",
        "        master_lis.append(list(np.concatenate(lis).flat))\n",
        "    arr = np.array(master_lis)\n",
        "    np.savetxt(\"/content/drive/MyDrive/BTP/DataSet/sq_shapes_v1.csv\",arr.reshape(arr.shape[0], -1) ,delimiter=',',\n",
        "               header=\"p1y,p1x,p2y,p2x,p3y,p3x,p4y,p4x,p5y,p5x,grId\",comments='')\n",
        "    return\n",
        "\n",
        "def save_sq_coords_v2(df,dx=5,dy=5):\n",
        "\n",
        "    def give_polygon_boundary_v2(pos,grId):\n",
        "        lon,lat = pos\n",
        "        x,y = [],[]\n",
        "        for _,row in df[df['grId']==grId].iterrows():\n",
        "            x_,y_ = row.geometry.exterior.coords.xy\n",
        "            x.extend(list(x_))\n",
        "            y.extend(list(y_))\n",
        "        min_lon,max_lon = min(x),max(x)\n",
        "        min_lat,max_lat = min(y),max(y)\n",
        "        #+/- 0.02 to both (+/- 1km)\n",
        "        min_lon -= 0.02\n",
        "        max_lon += 0.02\n",
        "        min_lat -= 0.02\n",
        "        max_lat += 0.02\n",
        "        return [[min_lon,min_lat],[min_lon,max_lat],[max_lon,max_lat],[max_lon,min_lat],[min_lon,min_lat]]\n",
        "\n",
        "    group_ids = df['grId'].unique()\n",
        "    master_lis = []\n",
        "    for grId in group_ids:\n",
        "        lon,lat = give_avg(grId,df)\n",
        "        lis = give_polygon_boundary_v2((lon,lat),grId)\n",
        "        lis.append([grId])\n",
        "        master_lis.append(list(np.concatenate(lis).flat))\n",
        "\n",
        "    arr = np.array(master_lis)\n",
        "    np.savetxt(\"/content/drive/MyDrive/BTP/DataSet/brazil_sq_shapes_v2.csv\",arr.reshape(arr.shape[0], -1) ,delimiter=',',\n",
        "               header=\"p1y,p1x,p2y,p2x,p3y,p3x,p4y,p4x,p5y,p5x,grId\",comments='')\n",
        "        \n",
        "\n",
        "save_sq_coords_v2(new_df,10,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "VrQ3SDftbXRl",
        "outputId": "1723159c-f4fb-444b-d7ab-e155cafed9b9"
      },
      "source": [
        "#reading already saved shape_df\n",
        "shape_df = pd.read_csv(\"/content/drive/MyDrive/BTP/DataSet/brazil_sq_shapes_v2.csv\")\n",
        "shape_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "816Ra1vKbcFu"
      },
      "source": [
        "# Making Image of Square Shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPCZ1lX-baSj",
        "outputId": "ea56d6b4-b9d7-406d-cc0c-801ced809d8c"
      },
      "source": [
        "import ee\n",
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymwKCu5zbdxd"
      },
      "source": [
        "def maskS2clouds(image):\n",
        "    qa = image.select('QA60')\n",
        "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
        "    cloudBitMask = 1 << 10\n",
        "    cirrusBitMask = 1 << 11\n",
        "\n",
        "    # Both flags should be set to zero, indicating clear conditions.\n",
        "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
        "\n",
        "    return image.updateMask(mask).divide(10000)\n",
        "  \n",
        "dataset = ee.ImageCollection('COPERNICUS/S2_SR').filterDate('2019-01-01', '2019-12-31').filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20)).map(maskS2clouds);\n",
        "# visualization = {\n",
        "#     \"min\": 0,\n",
        "#     \"max\": 255,\n",
        "#     \"bands\": ['B1','B2', 'B3', 'B4','B5','B6', 'B7', 'B8','B8A','B9', 'B11', 'B12']\n",
        "#     }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2jxjvjDbo8v",
        "outputId": "f8ec56cf-42f2-48a8-cce8-3144439b06cd"
      },
      "source": [
        "shapes = []\n",
        "group_ids = shape_df['grId'].unique()\n",
        "print(group_ids)\n",
        "for id in group_ids:\n",
        "    temp_df = shape_df[shape_df['grId']==id]\n",
        "    assert temp_df.shape[0]==1\n",
        "    geometry = ee.Geometry.Polygon([[temp_df.iloc[0,0],temp_df.iloc[0,1]],\n",
        "                                    [temp_df.iloc[0,2],temp_df.iloc[0,3]],\n",
        "                                    [temp_df.iloc[0,4],temp_df.iloc[0,5]],\n",
        "                                    [temp_df.iloc[0,6],temp_df.iloc[0,7]],\n",
        "                                    [temp_df.iloc[0,8],temp_df.iloc[0,9]]])\n",
        "    shapes.append(geometry)\n",
        "shapes[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOTF1E8ebvU6"
      },
      "source": [
        "# sentinel = dataset.median().clip(geometry)\n",
        "clips = []\n",
        "for shp in shapes:\n",
        "    clip = dataset.median().clip(shp)\n",
        "    clips.append(clip)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "9ZF2njLTb642",
        "outputId": "497fe45f-3714-4dc4-ca54-3f6b3604ac69"
      },
      "source": [
        "# Uncomment to visualize\n",
        "# Not required \n",
        "\"\"\"\n",
        "# Import the Folium library.\n",
        "import folium\n",
        "\n",
        "# Define a method for displaying Earth Engine image tiles to folium map.\n",
        "def add_ee_layer(self, ee_image_object, vis_params, name):\n",
        "  map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
        "  folium.raster_layers.TileLayer(\n",
        "    tiles = map_id_dict['tile_fetcher'].url_format,\n",
        "    attr = 'Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    name = name,\n",
        "    overlay = True,\n",
        "    control = True\n",
        "  ).add_to(self)\n",
        "\n",
        "# Add EE drawing method to folium.\n",
        "folium.Map.add_ee_layer = add_ee_layer\n",
        "\n",
        "# Set visualization parameters.\n",
        "# vis_params = {\n",
        "#   'min': 0,\n",
        "#   'max': 4000,\n",
        "#   'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5']}\n",
        "\n",
        "my_map = folium.Map(location=[20, 0], zoom_start=3, height=500)\n",
        "my_map.add_ee_layer(sentinel, visualization, 'RGB');\n",
        "# Display the map.\n",
        "display(my_map)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dhKmq_5b_bK"
      },
      "source": [
        "# Exporting Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_JGecs2b8nT"
      },
      "source": [
        "tasks = []\n",
        "\n",
        "#Making tasks\n",
        "for i in range(len(clips)):\n",
        "    task = ee.batch.Export.image.toDrive(\n",
        "    image=clips[i].select(['B1','B2', 'B3', 'B4','B5','B6', 'B7', 'B8','B8A','B9', 'B11', 'B12']),\n",
        "    description=\"BRA-\"+str(int(group_ids[i])),   \n",
        "    scale=10,\n",
        "    region=shapes[i],\n",
        "    folder='Brazil_Images',\n",
        "    crs=\"EPSG:4326\"\n",
        "    )\n",
        "    tasks.append(task)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f000cumTcBan"
      },
      "source": [
        "#Starting Tasks\n",
        "for i in range(len(tasks)):\n",
        "    tasks[i].start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkwD4ZBal2hi"
      },
      "source": [
        "#Task status\n",
        "running = []\n",
        "ready = tasks.copy()\n",
        "completed = [] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4namFcacDh-",
        "outputId": "c821efb3-3228-4e60-f2fd-9d09451f3d46"
      },
      "source": [
        "for task in ready:\n",
        "    if task.status()['state']=='COMPLETED':\n",
        "        completed.append(task)\n",
        "        ready.remove(task)\n",
        "    elif task.status()['state']=='RUNNING':\n",
        "        running.append(task)\n",
        "        ready.remove(task)\n",
        "\n",
        "for task in running:\n",
        "    if task.status()['state']=='COMPLETED':\n",
        "        completed.append(task)\n",
        "        running.remove(task)\n",
        "\n",
        "print(\"Current Running: \",len(running),\" Completed: \",len(completed), \" Yet to start: \",len(ready),\" Total: \",len(tasks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acavRqjccKY5"
      },
      "source": [
        "# Generating Masks of Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhJ8595vcJ-F"
      },
      "source": [
        "base_path = \"/content/drive/MyDrive/BTP/Imagesv1/\"\n",
        "\n",
        "#do for each image/group\n",
        "for img_name in os.listdir(base_path):\n",
        "    img_name_ = os.path.splitext(img_name)[0]\n",
        "    img_path = base_path + img_name\n",
        "    \n",
        "    with rasterio.open(img_path, \"r\") as src:\n",
        "        raster_img = src.read()\n",
        "        # rasterio.plot.show(src,cmap=\"pink\")\n",
        "        raster_meta = src.meta\n",
        "\n",
        "    grId = int(img_name_.split('-')[1])\n",
        "\n",
        "    #train_df generation from new_df\n",
        "    train_df = new_df[new_df['grId']==grId]\n",
        "    #Generate polygon\n",
        "    def poly_from_utm(polygon, transform):\n",
        "        poly_pts = []\n",
        "        \n",
        "        poly = cascaded_union(polygon)\n",
        "        for i in np.array(poly.exterior.coords):\n",
        "            \n",
        "            # Convert polygons to the image CRS\n",
        "            poly_pts.append(~transform * tuple(i))\n",
        "            \n",
        "        # Generate a polygon object\n",
        "        new_poly = Polygon(poly_pts)\n",
        "        return new_poly\n",
        "    \n",
        "    poly_shp = []\n",
        "    im_size = (src.meta['height'], src.meta['width'])\n",
        "    for num, row in train_df.iterrows():\n",
        "        if row['geometry'].geom_type == 'Polygon':\n",
        "            poly = poly_from_utm(row['geometry'], src.meta['transform'])\n",
        "            poly_shp.append(poly)\n",
        "        else:\n",
        "            for p in row['geometry']:\n",
        "                poly = poly_from_utm(p, src.meta['transform'])\n",
        "                poly_shp.append(poly)\n",
        "\n",
        "    mask = rasterize(shapes=poly_shp,\n",
        "                    out_shape=im_size)\n",
        "    mask = mask*255\n",
        "    # Plot the mask\n",
        "    # plt.figure(figsize=(5,5))\n",
        "    # plt.imshow(mask,cmap=\"gray\")\n",
        "\n",
        "    cv2.imwrite(\"/content/drive/MyDrive/BTP/Masksv1/\"+img_name_+\".png\",mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Visualizing RGB files from tif files"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "LGT79zL1H430"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6MFJ3JeRDXW"
      },
      "source": [
        "base_path = \"/content/drive/MyDrive/BTP/Imagesv1/\"\n",
        "image = clips[0].select(['B4', 'B3', 'B2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLXDMaj0ISoc",
        "outputId": "63240bd7-bc36-4cad-8743-ad1812c00ed8"
      },
      "source": [
        "imageRGB = image.visualize(['B5', 'B4', 'B3'], 0.5)\n",
        "imageRGB"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}